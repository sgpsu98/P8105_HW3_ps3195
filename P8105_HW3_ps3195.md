P8105\_HW3
================
Pengyuan Su (ps3195)
10/8/2020

## Problem 1

``` r
data("instacart")
```

This dataset contains 1384617 rows and 15 columns.

Observations are the level of items in orders by user. There are user /
order variables – user ID, order ID, order day, and order hour. There
are also item variables – name, aisle, department, and some numeric
codes.

``` r
instacart %>% 
    count(aisle) %>% 
    arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ... with 124 more rows

Make a plot

``` r
instacart %>% 
    count(aisle) %>% 
    filter(n > 10000) %>% 
    mutate(
        aisle = factor(aisle),
        aisle = fct_reorder(aisle, n)
    ) %>% 
    ggplot(aes(x = aisle, y = n)) + 
    geom_point() + 
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<img src="P8105_HW3_ps3195_files/figure-gfm/aisle-1.png" width="90%" />

Make a table\!\!

``` r
instacart %>% 
    filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
    group_by(aisle) %>% 
    count(product_name) %>% 
    mutate(rank = min_rank(desc(n))) %>% 
    filter(rank < 4) %>% 
    arrange(aisle, rank) %>% 
    knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

Apples vs ice cream..

``` r
instacart %>% 
    filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
    group_by(product_name, order_dow) %>% 
    summarize(mean_hour = mean(order_hour_of_day)) %>% 
    pivot_wider(
        names_from = order_dow,
        values_from = mean_hour
    )
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

## Problem 2

``` r
path = "./data/accel_data.csv"
```

Read the accel\_data

``` r
accel_df = 
      read_csv(
             file = path,
      ) %>% 
      janitor::clean_names() %>% 
      mutate(day_type = recode(day, "Monday" = "Weekday", "Tuesday" = "weekday", "Wednesday" = "weekday", "Thursday" = "weekday", "Friday" = "weekday", "Saturday" = "weekend", "Sunday" = "weekend")) %>% 
      relocate(week, day_id, day, day_type) %>% 
      pivot_longer(
             activity_1:activity_1440,
               names_to = "minute",
               names_prefix = "activity_",
               values_to = "activity_counts"
      )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
week_df = 
  tibble(
    n_day = 0:6,
    day = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")
  )

accel_df = 
  left_join(accel_df, week_df, by = "day") %>% 
  mutate(n_date = week * 7 + n_day - 6,
         day = factor(day),
         day_type = factor(day_type),
         minute = as.numeric(minute)) %>% 
  relocate(n_date, week, day) %>%
  select(-n_day) %>% 
  arrange(n_date)
```

There are 7 variables. The names of the variables in `accel_df` are:
activity\_counts, day, day\_id, day\_type, minute, n\_date, week, and
there are 50400 observations in it.

Plot the relation between number of activities per day and the day:

``` r
plot_day =
  accel_df %>% 
  group_by(n_date, week) %>% 
  summarise(n_ac = sum(activity_counts)) %>% 
  ggplot(aes(x = n_date, y = n_ac, color = week)) +
        geom_point() + geom_line() +
  labs(x = "date", y = "Counts")
```

    ## `summarise()` regrouping output by 'n_date' (override with `.groups` argument)

``` r
plot_day
```

<img src="P8105_HW3_ps3195_files/figure-gfm/plot of day-1.png" width="90%" />

Make the table:

``` r
accel_df %>% 
  group_by(n_date, week, day) %>% 
  summarise(n_ac = sum(activity_counts)) %>% 
  knitr::kable(digits = 1)
```

    ## `summarise()` regrouping output by 'n_date', 'week' (override with `.groups` argument)

| n\_date | week | day       |    n\_ac |
| ------: | ---: | :-------- | -------: |
|       1 |    1 | Sunday    | 631105.0 |
|       2 |    1 | Monday    |  78828.1 |
|       3 |    1 | Tuesday   | 307094.2 |
|       4 |    1 | Wednesday | 340115.0 |
|       5 |    1 | Thursday  | 355923.6 |
|       6 |    1 | Friday    | 480542.6 |
|       7 |    1 | Saturday  | 376254.0 |
|       8 |    2 | Sunday    | 422018.0 |
|       9 |    2 | Monday    | 295431.0 |
|      10 |    2 | Tuesday   | 423245.0 |
|      11 |    2 | Wednesday | 440962.0 |
|      12 |    2 | Thursday  | 474048.0 |
|      13 |    2 | Friday    | 568839.0 |
|      14 |    2 | Saturday  | 607175.0 |
|      15 |    3 | Sunday    | 467052.0 |
|      16 |    3 | Monday    | 685910.0 |
|      17 |    3 | Tuesday   | 381507.0 |
|      18 |    3 | Wednesday | 468869.0 |
|      19 |    3 | Thursday  | 371230.0 |
|      20 |    3 | Friday    | 467420.0 |
|      21 |    3 | Saturday  | 382928.0 |
|      22 |    4 | Sunday    | 260617.0 |
|      23 |    4 | Monday    | 409450.0 |
|      24 |    4 | Tuesday   | 319568.0 |
|      25 |    4 | Wednesday | 434460.0 |
|      26 |    4 | Thursday  | 340291.0 |
|      27 |    4 | Friday    | 154049.0 |
|      28 |    4 | Saturday  |   1440.0 |
|      29 |    5 | Sunday    | 138421.0 |
|      30 |    5 | Monday    | 389080.0 |
|      31 |    5 | Tuesday   | 367824.0 |
|      32 |    5 | Wednesday | 445366.0 |
|      33 |    5 | Thursday  | 549658.0 |
|      34 |    5 | Friday    | 620860.0 |
|      35 |    5 | Saturday  |   1440.0 |

According to the plot and the table, the number of activities per day
shows in fluctuate.

  - week 1: the number of activities firstly drops and then increases
    from Monday to Friday and decreases when enter the weekend.

  - week 2: the number of activities firstly decreases from Sunday to
    Monday and increases during the rest.

  - week 3: the number of activities firstly increase when day comes to
    weekday and then decrease on Tuesday, then it shows fluctuate.

  - week 4: the number of activities firstly shows in fluctuate and
    decreases from Wednesday to Saturday.

  - week 5: the number of activities increases from Sunday to Friday and
    decreases on Saturday.

According to the weeks, activities seems to increase from week 1 to 3
and decrease in week 4 and 5.

``` r
plot_hour =
  accel_df %>%
  group_by(week) %>% 
  ggplot(aes(x = minute, y = activity_counts, color = n_date)) +
  geom_point() + geom_line() +
  scale_y_continuous(name = "Activity counts in minutes") +
  scale_x_continuous(name = "Hour",
                     breaks = c(120, 240, 360, 480, 600, 720, 840, 960, 1080, 1200, 1320, 1440), 
                     labels = c("2h", "4h", "6h", "8h", "10h", "12h","14h", "16h", "18h","20h", "22h", "24h")
                     ) +
  labs(
    title = "The 24-hour activity counts in 35 days",
    caption = "Data from accelerometer data",
    color = "date"
    ) 

plot_hour
```

<img src="P8105_HW3_ps3195_files/figure-gfm/plot of 24 hour-1.png" width="90%" />

*Conclusion:* The `plot_hour` shows that the 63-year-old man usually
take activities during 6am to 10pm, and he firstly act most at around
11.30 am and 9 pm, but when days go through, he act more likely at 7 am
and 9 pm.

## Problem 3

``` r
data("ny_noaa")
```

``` r
noaa_df =
  ny_noaa %>% 
  janitor::clean_names() %>%
  mutate_at(vars(prcp, tmax, tmin, snow, snwd), as.numeric) %>% 
  mutate(id = factor(id),
         prcp = prcp / 10,
         tmin = tmin / 10,
         tmax = tmax / 10,
         snow = case_when(
             snow <0 ~ 0,
             snow >= 0 ~ snow
         )
         ) %>% 
  separate(date, c("year", "month", "day"), sep = "([-])") %>% 
  mutate_at(vars(year, month, day), as.factor)

skimr::skim_without_charts(noaa_df)
```

|                                                  |          |
| :----------------------------------------------- | :------- |
| Name                                             | noaa\_df |
| Number of rows                                   | 2595176  |
| Number of columns                                | 9        |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |          |
| Column type frequency:                           |          |
| factor                                           | 4        |
| numeric                                          | 5        |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |          |
| Group variables                                  | None     |

Data summary

**Variable type: factor**

| skim\_variable | n\_missing | complete\_rate | ordered | n\_unique | top\_counts                                       |
| :------------- | ---------: | -------------: | :------ | --------: | :------------------------------------------------ |
| id             |          0 |              1 | FALSE   |       747 | USC: 10957, USC: 10957, USC: 10957, USC: 10957    |
| year           |          0 |              1 | FALSE   |        30 | 201: 159671, 200: 148721, 200: 122665, 200: 93249 |
| month          |          0 |              1 | FALSE   |        12 | 10: 224471, 12: 223603, 07: 220348, 08: 220100    |
| day            |          0 |              1 | FALSE   |        31 | 01: 85258, 02: 85258, 03: 85258, 04: 85258        |

**Variable type: numeric**

| skim\_variable | n\_missing | complete\_rate |  mean |     sd |     p0 |   p25 |  p50 |  p75 |  p100 |
| :------------- | ---------: | -------------: | ----: | -----: | -----: | ----: | ---: | ---: | ----: |
| prcp           |     145838 |           0.94 |  2.98 |   7.82 |    0.0 |   0.0 |  0.0 |  2.3 |  2286 |
| snow           |     381221 |           0.85 |  4.99 |  27.22 |    0.0 |   0.0 |  0.0 |  0.0 | 10160 |
| snwd           |     591786 |           0.77 | 37.31 | 113.54 |    0.0 |   0.0 |  0.0 |  0.0 |  9195 |
| tmax           |    1134358 |           0.56 | 13.98 |  11.14 | \-38.9 |   5.0 | 15.0 | 23.3 |    60 |
| tmin           |    1134420 |           0.56 |  3.03 |  10.40 | \-59.4 | \-3.9 |  3.3 | 11.1 |    60 |

The `ny_noaa` package has 2595176 rows and 9 columns. It has the data of
weather conditions for all New York state weather stations from January
1, 1981 through December 31, 2010. The variables in it are
`ls(noaa_df)`. `prcp`, `snow`, `snwd`, `tmax`, `tmin` have the missing
values. The missing proportion of them: prcp(0.0088087), snow(0.146896),
snwd(0.2280331), tmax(0.4371025), and tmin(0.4371264). `snow` and `snwd`
are high while `tmax` and `tmin` are extremely high\!

``` r
noaa_df %>% 
  count(snow) %>% 
  arrange(desc(n))
```

    ## # A tibble: 281 x 2
    ##     snow       n
    ##    <dbl>   <int>
    ##  1     0 2008509
    ##  2    NA  381221
    ##  3    25   31022
    ##  4    13   23095
    ##  5    51   18274
    ##  6    76   10173
    ##  7     8    9962
    ##  8     5    9748
    ##  9    38    9197
    ## 10     3    8790
    ## # ... with 271 more rows

It is shown that 0 is the most commonly observed values, which means
that no snowfall could be the common situation from 1981 to 2010 in New
York.

``` r
January = 
  noaa_df %>% 
  group_by(id, year, month) %>% 
  filter(month == "01") %>% 
  summarise(tmax_mean = mean(tmax, na.rm = T)) %>% 
  drop_na() %>% 
  ggplot(aes(x = year, y = tmax_mean, color = id)) +   geom_point(alpha = 0.3) + 
  geom_path(aes(group = id), alpha = 0.3) +
  theme(
    legend.position = 'none',
    axis.text.x = element_text(angle = -90,
                                   vjust = 0.5,
                                   hjust = 1)
                              ) +
  labs(
    title = " Mean of Max temperature in July in each station ",
    x = "Year",
    y = "Mean of Temperature (C)"
  )
```

    ## `summarise()` regrouping output by 'id', 'year' (override with `.groups` argument)

``` r
July = 
  noaa_df %>% 
  group_by(id, year, month) %>% 
  filter(month == "07") %>% 
  summarise(tmax_mean = mean(tmax, na.rm = T)) %>% 
  drop_na() %>% 
  ggplot(aes(x = year, y = tmax_mean, color = id)) +   geom_point(alpha = 0.3) + 
  geom_path(aes(group = id), alpha = 0.3) +
  theme(
    legend.position = 'none',
    axis.text.x = element_text(angle = -90,
                                   vjust = 0.5,
                                   hjust = 1)
                              ) +
  labs(
    title = " Mean of Max temperature in July in each station ",
    x = "Year",
    y = "Mean of Temperature (C)"
  )
```

    ## `summarise()` regrouping output by 'id', 'year' (override with `.groups` argument)

``` r
January / July
```

<img src="P8105_HW3_ps3195_files/figure-gfm/January vs July-1.png" width="90%" />

According to the two-panel plot, we could see the difference of max
temperature in January and July,

  - January shows range around -10 to 10 while July has the range around
    20 to 32.5.

  - As for the January plot, 1994, 2004 are the two years which have
    relative low temperature while 1990, 1998, 2002, and 2006 have the
    relative high temperature. As for the July plot, 1992, 2000 have
    relative low temperature while 1983, 1999, and 2010 have the
    relative high temperature.

Outliers in January:

``` r
noaa_df %>% 
  filter(month == "01") %>% 
  group_by(id, year, month) %>% 
  summarise(tmax_mean = mean(tmax,na.rm = T)) %>% 
  drop_na() %>% 
  filter(tmax_mean > 10 | tmax_mean < -10) %>% 
  knitr::kable(digits = 1)
```

    ## `summarise()` regrouping output by 'id', 'year' (override with `.groups` argument)

| id          | year | month | tmax\_mean |
| :---------- | :--- | :---- | ---------: |
| USC00301723 | 1982 | 01    |     \-13.4 |
| USC00303464 | 1998 | 01    |       10.2 |
| USC00304996 | 1994 | 01    |     \-10.6 |
| USC00305925 | 2005 | 01    |     \-12.2 |
| USC00306957 | 2004 | 01    |     \-10.8 |
| USW00094725 | 1994 | 01    |     \-10.2 |
| USW00094725 | 2004 | 01    |     \-10.4 |
| USW00094740 | 2004 | 01    |     \-10.4 |

Outliers in July:

``` r
noaa_df %>% 
  filter(month == "07") %>% 
  group_by(id, year, month) %>% 
  summarise(tmax_mean = mean(tmax,na.rm = T)) %>% 
  drop_na() %>% 
  filter(tmax_mean > 32.5 | tmax_mean < 20) %>% 
  knitr::kable(digits = 1)
```

    ## `summarise()` regrouping output by 'id', 'year' (override with `.groups` argument)

| id          | year | month | tmax\_mean |
| :---------- | :--- | :---- | ---------: |
| USC00302454 | 2004 | 07    |       18.3 |
| USC00304025 | 1999 | 07    |       32.5 |
| USC00305377 | 2010 | 07    |       33.6 |
| USC00306957 | 2000 | 07    |       19.8 |
| USC00308248 | 2000 | 07    |       19.9 |
| USC00308946 | 1984 | 07    |       19.1 |
| USC00308946 | 2010 | 07    |       32.7 |
| USC00308962 | 1988 | 07    |       14.0 |
| USC00309292 | 1999 | 07    |       32.8 |
| USC00309389 | 2007 | 07    |       19.2 |
| USW00014732 | 2010 | 07    |       32.6 |

``` r
t = 
  noaa_df %>% 
  pivot_longer(
    tmax:tmin,
    names_to = "t_type",
    values_to = "temperature"
  ) %>% 
  ggplot(aes(x = year, y = temperature, color = t_type)) +
  geom_boxplot(aes(alpha = 0.6, outlier.size = 0.2)) +
  theme(
    legend.position = 'right',
    axis.text.x = element_text(
                               angle = -90,
                               vjust = 0.5,
                               size = 8,
                               hjust = 1
                               ),
    axis.text.y = element_text(size = 8)
       ) +
  scale_y_continuous(breaks = c(-60, -50, -40, -30, -20, -10, 0, 10, 20, 30, 40, 50, 60)) +
  labs(
    x = "Year",
    y = "Temperature (C)",
    title = "Tmax vs Tmin"
    )
```

    ## Warning: Ignoring unknown aesthetics: outlier.size

``` r
snowf = 
  noaa_df %>%
  filter(snow > 0 & snow < 100, !is.na(snow)) %>% 
  ggplot(aes(x = snow)) +
  geom_density_ridges(aes(y = year, group = year),
                      alpha = 0.2,
                      rel_min_height = 0.15) +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = -90,
                                   vjust = 0.5,
                                   hjust = 1)) +
  scale_x_continuous(breaks = c(10, 20, 30, 40, 50, 60, 70, 80)) +
  coord_flip() +
  labs(
    title = "Density for Snowfall between 0mm to 100mm",
    subtitle = "1981-2010 in New York state",
    x = "Snowfall (mm)",
    y = "Years"
  )
  
  
  t + snowf
```

    ## Warning: Removed 2268778 rows containing non-finite values (stat_boxplot).

    ## Picking joint bandwidth of 3.76

<img src="P8105_HW3_ps3195_files/figure-gfm/Tmax vs Tmin and snowfall-1.png" width="90%" />

  - According to the t plot, there seems to be no change during the
    years, and the difference between tmax and tmin is range from 12C to
    15C, hence it could not make a conclusion about global warming.

  - According to the density of snowfall, we could find that three main
    range of snowfall are 5-15(mm), 20-30(mm), and 45-55(mm). However,
    we could see that the proportion of 5-15(mm) increases more and
    gradually become higher than the other two during the period. Though
    not significant enough, we could see the influence of golbal
    warming…
